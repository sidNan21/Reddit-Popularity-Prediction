{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some common packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_json('../data/relationship_advice.json')\n",
    "data['distinguished'] = data['distinguished'].fillna(value='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for categorization criteria (see `playground.ipynb` for detailed explanation)\n",
    "\n",
    "# compute boundaries\n",
    "def compute_bounds(data):\n",
    "    res  = dict()\n",
    "    P_90 = np.percentile(data,90)\n",
    "    # excluding forall d <= 0\n",
    "    log_data = np.log([d for d in data if d > P_90])\n",
    "    res['INSIGNIFICANT'] = np.exp(np.percentile(log_data, 0)) # equivalent to np.percentile(data, 90)\n",
    "    res['NOTABLE']       = np.exp(np.percentile(log_data, 60))\n",
    "    res['SIGNIFICANT']   = np.exp(np.percentile(log_data, 90))\n",
    "    res['POPULAR']       = np.exp(np.percentile(log_data, 99.0))\n",
    "    # implicit 'VERY POPULAR'\n",
    "    return res\n",
    "    \n",
    "# autocategorization\n",
    "def categorize(d, bounds):\n",
    "    # try all categories\n",
    "    for cat, val in bounds.items():\n",
    "        if d < val:\n",
    "            return cat\n",
    "    # if at this point, VERY POPULAR\n",
    "    return 'VERY POPULAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data and generate features\n",
    "import afinn\n",
    "\n",
    "afinn_nlp = afinn.Afinn(language='en', emoticons=True)\n",
    "data['sentiment'] = data['body'].apply(lambda text: afinn_nlp.score(text))\n",
    "\n",
    "data['word_count'] = data['body'].apply(lambda text: len(text.split(' ')))\n",
    "data['char_count'] = data['body'].apply(lambda text: len(text))\n",
    "\n",
    "# categorize using defined boundaries (lambda now accepts bounds param, which is a dict)\n",
    "bounds = compute_bounds(data['score'])\n",
    "data['score_cat'] = data['score'].apply(lambda score: categorize(score, bounds))\n",
    "\n",
    "\n",
    "### DEPRECATED\n",
    "# def categorize(score):\n",
    "#     if score < 0:\n",
    "#         return 'UNPOPULAR'\n",
    "#     elif score >= 0 and score < 100:\n",
    "#         return 'UNREMARKABLE'\n",
    "#     elif score >= 100 and score < 500:\n",
    "#         return 'SOMEWHAT POPULAR'\n",
    "#     elif score >= 500 and score < 1000:\n",
    "#         return 'POPULAR'\n",
    "#     else:\n",
    "#         return 'VERY POPULAR'\n",
    "# data['score_cat'] = data['score'].apply(lambda score: categorize(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(stop_words='english', sublinear_tf=True)\n",
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "\n",
    "tr_scores, tr_comments, tr_meta = train['score_cat'], train['body'], train.drop(columns=['id', 'parent_id', 'top_level', 'created_utc', 'body', 'score', 'score_cat'])\n",
    "tst_scores, tst_comments, tst_meta = test['score_cat'], test['body'], test.drop(columns=['id', 'parent_id', 'top_level', 'created_utc', 'body', 'score', 'score_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "features = data.drop(columns=['id', 'parent_id', 'top_level', 'created_utc', 'body', 'score', 'score_cat'])\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', StandardScaler(), list(features.select_dtypes(include=[np.number]))),\n",
    "    ('cat', OneHotEncoder(), list(features.select_dtypes(include=[np.object]).columns))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_comments = tf.fit_transform(tr_comments)\n",
    "x_tst_comments = tf.transform(tst_comments)\n",
    "\n",
    "x_tr_meta = full_pipeline.fit_transform(tr_meta)\n",
    "x_tst_meta = full_pipeline.transform(tst_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "dt_comm = DecisionTreeClassifier(criterion='entropy')\n",
    "dt_comm.fit(x_tr_comments, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DT  based on TFIDF:  0.8471832303949093\n",
      "Precision of the DT based on TFIDF:  0.8236240923016687\n",
      "Recall of the DT based on TFIDF:  0.8471832303949093\n",
      "F-Score of the DT based on TFIDF:  0.8350640828659\n"
     ]
    }
   ],
   "source": [
    "comm_pred = dt_comm.predict(x_tst_comments)\n",
    "print(\"Accuracy of the DT  based on TFIDF: \", accuracy_score(tst_scores, comm_pred))\n",
    "print(\"Precision of the DT based on TFIDF: \", precision_score(tst_scores, comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the DT based on TFIDF: \", recall_score(tst_scores, comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the DT based on TFIDF: \", f1_score(tst_scores, comm_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_meta = DecisionTreeClassifier()\n",
    "dt_meta.fit(x_tr_meta, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DT based on metadata:  0.8323039490922702\n",
      "Precision of the DT based on TFIDF:  0.8399249090218797\n",
      "Recall of the DT based on TFIDF:  0.8323039490922702\n",
      "F-Score of the DT based on TFIDF:  0.8360634007792708\n"
     ]
    }
   ],
   "source": [
    "meta_pred = dt_meta.predict(x_tst_meta)\n",
    "print(\"Accuracy of the DT based on metadata: \", accuracy_score(tst_scores, meta_pred))\n",
    "print(\"Precision of the DT based on TFIDF: \", precision_score(tst_scores, meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the DT based on TFIDF: \", recall_score(tst_scores, meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the DT based on TFIDF: \", f1_score(tst_scores, meta_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_comm = RandomForestClassifier(criterion='entropy')\n",
    "rf_comm.fit(x_tr_comments, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the RF based on TFIDF:  0.9011791128579449\n",
      "Precision of the RF based on TFIDF:  0.8248221972674527\n",
      "Recall of the RF based on TFIDF:  0.9011791128579449\n",
      "F-Score of the RF based on TFIDF:  0.8554432099835828\n"
     ]
    }
   ],
   "source": [
    "rf_comm_pred = rf_comm.predict(x_tst_comments)\n",
    "print(\"Accuracy of the RF based on TFIDF: \", accuracy_score(tst_scores, rf_comm_pred))\n",
    "print(\"Precision of the RF based on TFIDF: \", precision_score(tst_scores, rf_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the RF based on TFIDF: \", recall_score(tst_scores, rf_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the RF based on TFIDF: \", f1_score(tst_scores, rf_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_meta = RandomForestClassifier()\n",
    "rf_meta.fit(x_tr_meta, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the RF based on metadata:  0.9000561482313307\n",
      "Precision of the RF based on metadata:  0.846429791137966\n",
      "Recall of the RF based on metadata:  0.9000561482313307\n",
      "F-Score of the RF based on metadata:  0.8608338364312814\n"
     ]
    }
   ],
   "source": [
    "rf_meta_pred = rf_meta.predict(x_tst_meta)\n",
    "print(\"Accuracy of the RF based on metadata: \", accuracy_score(tst_scores, rf_meta_pred))\n",
    "print(\"Precision of the RF based on metadata: \", precision_score(tst_scores, rf_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the RF based on metadata: \", recall_score(tst_scores, rf_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the RF based on metadata: \", f1_score(tst_scores, rf_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
