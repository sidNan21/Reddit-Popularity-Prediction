{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some common packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_json('../data/relationship_advice.json')\n",
    "data['distinguished'] = data['distinguished'].fillna(value='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for categorization criteria (see `playground.ipynb` for detailed explanation)\n",
    "\n",
    "# compute boundaries\n",
    "def compute_bounds(data):\n",
    "    res  = dict()\n",
    "    P_90 = np.percentile(data,90)\n",
    "    # excluding forall d <= 0\n",
    "    log_data = np.log([d for d in data if d > P_90])\n",
    "    res['INSIGNIFICANT'] = np.exp(np.percentile(log_data, 0)) # equivalent to np.percentile(data, 90)\n",
    "    res['NOTABLE']       = np.exp(np.percentile(log_data, 60))\n",
    "    res['SIGNIFICANT']   = np.exp(np.percentile(log_data, 90))\n",
    "    res['POPULAR']       = np.exp(np.percentile(log_data, 99.0))\n",
    "    # implicit 'VERY POPULAR'\n",
    "    return res\n",
    "    \n",
    "# autocategorization\n",
    "def categorize(d, bounds):\n",
    "    # try all categories\n",
    "    for cat, val in bounds.items():\n",
    "        if d < val:\n",
    "            return cat\n",
    "    # if at this point, VERY POPULAR\n",
    "    return 'VERY POPULAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data and generate features\n",
    "import afinn\n",
    "\n",
    "afinn_nlp = afinn.Afinn(language='en', emoticons=True)\n",
    "data['sentiment'] = data['body'].apply(lambda text: afinn_nlp.score(text))\n",
    "\n",
    "data['word_count'] = data['body'].apply(lambda text: len(text.split(' ')))\n",
    "data['char_count'] = data['body'].apply(lambda text: len(text))\n",
    "\n",
    "# categorize using defined boundaries (lambda now accepts bounds param, which is a dict)\n",
    "bounds = compute_bounds(data['score'])\n",
    "data['score_cat'] = data['score'].apply(lambda score: categorize(score, bounds))\n",
    "\n",
    "\n",
    "### DEPRECATED\n",
    "# def categorize(score):\n",
    "#     if score < 0:\n",
    "#         return 'UNPOPULAR'\n",
    "#     elif score >= 0 and score < 100:\n",
    "#         return 'UNREMARKABLE'\n",
    "#     elif score >= 100 and score < 500:\n",
    "#         return 'SOMEWHAT POPULAR'\n",
    "#     elif score >= 500 and score < 1000:\n",
    "#         return 'POPULAR'\n",
    "#     else:\n",
    "#         return 'VERY POPULAR'\n",
    "# data['score_cat'] = data['score'].apply(lambda score: categorize(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(stop_words='english', sublinear_tf=True)\n",
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "\n",
    "tr_scores, tr_comments, tr_meta = train['score_cat'], train['body'], train.drop(columns=['id', 'parent_id', 'top_level', 'created_utc', 'body', 'score', 'score_cat'])\n",
    "tst_scores, tst_comments, tst_meta = test['score_cat'], test['body'], test.drop(columns=['id', 'parent_id', 'top_level', 'created_utc', 'body', 'score', 'score_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "features = data.drop(columns=['id', 'parent_id', 'top_level', 'created_utc', 'body', 'score', 'score_cat'])\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', StandardScaler(), list(features.select_dtypes(include=[np.number]))),\n",
    "    ('cat', OneHotEncoder(), list(features.select_dtypes(include=[np.object]).columns))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_comments = tf.fit_transform(tr_comments)\n",
    "x_tst_comments = tf.transform(tst_comments)\n",
    "\n",
    "x_tr_meta = full_pipeline.fit_transform(tr_meta)\n",
    "x_tst_meta = full_pipeline.transform(tst_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "dt_comm = DecisionTreeClassifier()\n",
    "dt_comm.fit(x_tr_comments, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DT  based on TFIDF:  0.849769238014505\n",
      "Precision of the DT based on TFIDF:  0.8268327829906992\n",
      "Recall of the DT based on TFIDF:  0.849769238014505\n",
      "F-Score of the DT based on TFIDF:  0.8379446618785816\n"
     ]
    }
   ],
   "source": [
    "comm_pred = dt_comm.predict(x_tst_comments)\n",
    "print(\"Accuracy of the DT  based on TFIDF: \", accuracy_score(tst_scores, comm_pred))\n",
    "print(\"Precision of the DT based on TFIDF: \", precision_score(tst_scores, comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the DT based on TFIDF: \", recall_score(tst_scores, comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the DT based on TFIDF: \", f1_score(tst_scores, comm_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_meta = DecisionTreeClassifier()\n",
    "dt_meta.fit(x_tr_meta, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DT based on metadata:  0.8304605820853348\n",
      "Precision of the DT based on metadata:  0.8424793732899176\n",
      "Recall of the DT based on metadata:  0.8304605820853348\n",
      "F-Score of the DT based on metadata:  0.8363510942323107\n"
     ]
    }
   ],
   "source": [
    "meta_pred = dt_meta.predict(x_tst_meta)\n",
    "print(\"Accuracy of the DT based on metadata: \", accuracy_score(tst_scores, meta_pred))\n",
    "print(\"Precision of the DT based on metadata: \", precision_score(tst_scores, meta_pred, p)\n",
    "print(\"Recall of the DT based on metadata: \", recall_score(tst_scores, meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the DT based on metadata: \", f1_score(tst_scores, meta_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try using grid search on decision tree for optimizing hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# choose params to try + optimize\n",
    "param_grid = {\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "# classifier and grid search definition\n",
    "dt_comm_opt = DecisionTreeClassifier()\n",
    "dt_meta_opt = DecisionTreeClassifier()\n",
    "grid_comm = GridSearchCV(dt_comm_opt, param_grid)\n",
    "grid_meta = GridSearchCV(dt_meta_opt, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and search\n",
    "grid_comm.fit(x_tr_comments, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and search\n",
    "grid_meta.fit(x_tr_meta, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for comm\n",
      "Best max_depth: 2\n",
      "Best criterion: entropy\n",
      "[0.90169531 0.90169531 0.90193077 0.90168374 0.90180148]\n"
     ]
    }
   ],
   "source": [
    "# basic info\n",
    "print('Results for comm')\n",
    "print('Best max_depth:', grid_comm.best_estimator_.get_params()['max_depth'])\n",
    "print('Best criterion:', grid_comm.best_estimator_.get_params()['criterion'])\n",
    "\n",
    "# cross validation\n",
    "results = cross_val_score(grid_comm, x_tr_comments, tr_scores)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for meta\n",
      "Best max_depth: 4\n",
      "Best criterion: gini\n",
      "[0.9020485  0.90134212 0.90216623 0.90203697 0.90180148]\n"
     ]
    }
   ],
   "source": [
    "# basic info\n",
    "print('Results for meta')\n",
    "print('Best max_depth:', grid_meta.best_estimator_.get_params()['max_depth'])\n",
    "print('Best criterion:', grid_meta.best_estimator_.get_params()['criterion'])\n",
    "\n",
    "# cross validation\n",
    "results = cross_val_score(grid_meta, x_tr_meta, tr_scores)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "ada_comm = AdaBoostClassifier()\n",
    "ada_comm.fit(x_tr_comments, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Adaboost based on TFIDF:  0.9023264575680512\n",
      "Precision of the Adaboost based on TFIDF:  0.8152404733503618\n",
      "Recall of the Adaboost based on TFIDF:  0.9023264575680512\n",
      "F-Score of the Adaboost based on TFIDF:  0.8565757003611943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cory\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "ada_comm_pred = ada_comm.predict(x_tst_comments)\n",
    "print(\"Accuracy of the Adaboost based on TFIDF: \", accuracy_score(tst_scores, ada_comm_pred))\n",
    "print(\"Precision of the Adaboost based on TFIDF: \", precision_score(tst_scores, ada_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the Adaboost based on TFIDF: \", recall_score(tst_scores, ada_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the Adaboost based on TFIDF: \", f1_score(tst_scores, ada_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_meta = AdaBoostClassifier()\n",
    "ada_meta.fit(x_tr_meta, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Adaboost based on metadata:  0.9024206461335594\n",
      "Precision of the Adaboost based on metadata:  0.8280282360702597\n",
      "Recall of the Adaboost based on metadata:  0.9024206461335594\n",
      "F-Score of the Adaboost based on metadata:  0.8587000878693295\n"
     ]
    }
   ],
   "source": [
    "ada_meta_pred = ada_meta.predict(x_tst_meta)\n",
    "print(\"Accuracy of the Adaboost based on metadata: \", accuracy_score(tst_scores, ada_meta_pred))\n",
    "print(\"Precision of the Adaboost based on metadata: \", precision_score(tst_scores, ada_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the Adaboost based on metadata: \", recall_score(tst_scores, ada_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the Adaboost based on metadata: \", f1_score(tst_scores, ada_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_comm = GradientBoostingClassifier()\n",
    "gb_comm.fit(x_tr_comments, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GB based on TFIDF:  0.897711217858152\n",
      "Precision of the GB based on TFIDF:  0.8155344000160742\n",
      "Recall of the GB based on TFIDF:  0.897711217858152\n",
      "F-Score of the GB based on TFIDF:  0.8546376137659321\n"
     ]
    }
   ],
   "source": [
    "gb_comm_pred = gb_comm.predict(x_tst_comments)\n",
    "print(\"Accuracy of the GB based on TFIDF: \", accuracy_score(tst_scores, gb_comm_pred))\n",
    "print(\"Precision of the GB based on TFIDF: \", precision_score(tst_scores, gb_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the GB based on TFIDF: \", recall_score(tst_scores, gb_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the GB based on TFIDF: \", f1_score(tst_scores, gb_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_meta = GradientBoostingClassifier()\n",
    "gb_meta.fit(x_tr_meta, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GB based on metadata:  0.9033625317886409\n",
      "Precision of the GB based on metadata:  0.8575059756424817\n",
      "Recall of the GB based on metadata:  0.9033625317886409\n",
      "F-Score of the GB based on metadata:  0.8585857924605989\n"
     ]
    }
   ],
   "source": [
    "gb_meta_pred = gb_meta.predict(x_tst_meta)\n",
    "print(\"Accuracy of the GB based on metadata: \", accuracy_score(tst_scores, gb_meta_pred))\n",
    "print(\"Precision of the GB based on metadata: \", precision_score(tst_scores, gb_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the GB based on metadata: \", recall_score(tst_scores, gb_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the GB based on metadata: \", f1_score(tst_scores, gb_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_comm = RandomForestClassifier()\n",
    "rf_comm.fit(x_tr_comments, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the RF based on TFIDF:  0.8956390694169728\n",
      "Precision of the RF based on TFIDF:  0.8205424858590274\n",
      "Recall of the RF based on TFIDF:  0.8956390694169728\n",
      "F-Score of the RF based on TFIDF:  0.854316831211526\n"
     ]
    }
   ],
   "source": [
    "rf_comm_pred = rf_comm.predict(x_tst_comments)\n",
    "print(\"Accuracy of the RF based on TFIDF: \", accuracy_score(tst_scores, rf_comm_pred))\n",
    "print(\"Precision of the RF based on TFIDF: \", precision_score(tst_scores, rf_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the RF based on TFIDF: \", recall_score(tst_scores, rf_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the RF based on TFIDF: \", f1_score(tst_scores, rf_comm_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_meta = RandomForestClassifier()\n",
    "rf_meta.fit(x_tr_meta, tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the RF based on metadata:  0.8986531035132335\n",
      "Precision of the RF based on metadata:  0.8303348237541501\n",
      "Recall of the RF based on metadata:  0.8986531035132335\n",
      "F-Score of the RF based on metadata:  0.8587995663731227\n"
     ]
    }
   ],
   "source": [
    "rf_meta_pred = rf_meta.predict(x_tst_meta)\n",
    "print(\"Accuracy of the RF based on metadata: \", accuracy_score(tst_scores, rf_meta_pred))\n",
    "print(\"Precision of the RF based on metadata: \", precision_score(tst_scores, rf_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"Recall of the RF based on metadata: \", recall_score(tst_scores, rf_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))\n",
    "print(\"F-Score of the RF based on metadata: \", f1_score(tst_scores, rf_meta_pred, labels=list(set(data['score_cat'])), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
